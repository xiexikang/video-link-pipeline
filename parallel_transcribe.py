#!/usr/bin/env python3
"""
å¹¶è¡Œè¯­éŸ³è½¬å½•æ¨¡å— - ä½¿ç”¨ faster-whisper è¿›è¡Œé«˜æ•ˆçš„éŸ³é¢‘è½¬å½•
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import List, Optional, Tuple

import yaml
from tqdm import tqdm


def load_config(config_path: str = "config.yaml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if os.path.exists(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    return {}


def get_device_and_compute_type(config: dict) -> Tuple[str, str]:
    """æ ¹æ®é…ç½®è·å–è®¾å¤‡å’Œè®¡ç®—ç±»å‹"""
    whisper_config = config.get("whisper", {})
    device = whisper_config.get("device", "auto")
    compute_type = whisper_config.get("compute_type", "int8")
    return device, compute_type


import shutil

def setup_ffmpeg():
    """Ensure ffmpeg is in PATH"""
    # 1. å°è¯•ç›´æ¥æ£€æµ‹
    system_ffmpeg = shutil.which("ffmpeg")
    if system_ffmpeg:
        print(f"âœ… æ£€æµ‹åˆ°ç³»ç»Ÿ FFmpeg: {system_ffmpeg}")
        return

    # 2. ç‰¹æ®Šå¤„ç†ï¼šæ£€æµ‹å·²çŸ¥çš„ä¸­æ–‡è·¯å¾„ï¼ˆä¿®å¤ç¯å¢ƒå˜é‡ä¹±ç é—®é¢˜ï¼‰
    # ç”¨æˆ·ç¯å¢ƒå¯èƒ½å› ä¸ºè·¯å¾„åŒ…å«ä¸­æ–‡å¯¼è‡´ PATH è§£æå¤±è´¥
    known_paths = [
        r"G:\æŠ€æœ¯è½¯ä»¶\ffmpeg-master-latest-win64-gpl-shared\bin"
    ]
    for p in known_paths:
        if os.path.exists(p) and (Path(p) / "ffmpeg.exe").exists():
            print(f"ğŸ”„ æ£€æµ‹åˆ°ä¸­æ–‡è·¯å¾„ FFmpegï¼Œæ­£åœ¨ä¿®å¤ç¯å¢ƒå˜é‡: {p}")
            os.environ["PATH"] = p + os.pathsep + os.environ.get("PATH", "")
            # å†æ¬¡ç¡®è®¤
            if shutil.which("ffmpeg"):
                print(f"âœ… ç³»ç»Ÿ FFmpeg å·²ç”Ÿæ•ˆ: {shutil.which('ffmpeg')}")
                return

    print("âš ï¸ æœªæ£€æµ‹åˆ°ç³»ç»Ÿ FFmpegï¼Œæ­£åœ¨é…ç½®å†…ç½®ç¯å¢ƒ...")
    try:
        import imageio_ffmpeg as i_ffmpeg
        src_ffmpeg = i_ffmpeg.get_ffmpeg_exe()
        
        # Create local bin directory
        bin_dir = Path("./bin").resolve()
        bin_dir.mkdir(parents=True, exist_ok=True)
        
        dest_ffmpeg = bin_dir / "ffmpeg.exe"
        
        # Copy if not exists or different size
        if not dest_ffmpeg.exists() or dest_ffmpeg.stat().st_size != Path(src_ffmpeg).stat().st_size:
            print(f"å¤åˆ¶ ffmpeg åˆ°æœ¬åœ° bin ç›®å½•: {dest_ffmpeg}")
            shutil.copy2(src_ffmpeg, dest_ffmpeg)
            
        # Add to PATH
        os.environ["PATH"] = str(bin_dir) + os.pathsep + os.environ.get("PATH", "")
        print(f"å·²å°† ffmpeg æ·»åŠ åˆ° PATH: {bin_dir}")
        
    except Exception as e:
        print(f"é…ç½® ffmpeg å¤±è´¥: {e}")

def transcribe_audio(
    input_path: str,
    output_dir: str,
    model_size: str = "small",
    language: str = "auto",
    device: str = "auto",
    compute_type: str = "int8",
    engine: str = "auto",
) -> dict:
    """
    ä½¿ç”¨ faster-whisper æˆ– openai-whisper è½¬å½•éŸ³é¢‘
    
    Args:
        input_path: éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large-v1, large-v2, large-v3)
        language: è¯­è¨€ä»£ç  (auto ä¸ºè‡ªåŠ¨æ£€æµ‹)
        device: è®¡ç®—è®¾å¤‡ (cpu, cuda, auto)
        compute_type: è®¡ç®—ç±»å‹ (int8, float16, float32)
        engine: è½¬å½•å¼•æ“ (auto, faster_whisper, openai_whisper)
    
    Returns:
        dict: è½¬å½•ç»“æœ
    """
    setup_ffmpeg()
    
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    result = {
        "success": False,
        "transcript_file": None,
        "srt_file": None,
        "vtt_file": None,
        "segments": [],
        "detected_language": None,
        "error": None,
    }

    try:
        use_faster = True
        
        # ç¡®å®šä½¿ç”¨çš„å¼•æ“
        if engine == "openai_whisper":
            use_faster = False
        elif engine == "faster_whisper":
            use_faster = True
        else:
            # auto æ¨¡å¼ï¼Œå°è¯•å¯¼å…¥ faster-whisper
            try:
                import faster_whisper
                use_faster = True
            except ImportError:
                use_faster = False

        # å¦‚æœå†³å®šä½¿ç”¨ faster-whisperï¼Œå°è¯•å¯¼å…¥ WhisperModel
        if use_faster:
            try:
                from faster_whisper import WhisperModel
            except Exception as e:
                if engine == "faster_whisper":
                    # å¦‚æœç”¨æˆ·æ˜¾å¼æŒ‡å®šä½¿ç”¨ faster_whisperï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                    raise ImportError(f"æ— æ³•åŠ è½½ faster-whisper: {e}")
                
                print(f"âš ï¸ æ— æ³•åŠ è½½ faster-whisper: {e}")
                print("   æ­£åœ¨å›é€€åˆ° openai-whisper...")
                use_faster = False
        
        segments_list = []
        detected_language = None
        
        if use_faster:
            print(f"åŠ è½½ Whisper æ¨¡å‹ (faster-whisper): {model_size}")
            # ... existing faster-whisper logic ...
            model = WhisperModel(model_size, device=device, compute_type=compute_type)
            print(f"å¼€å§‹è½¬å½•: {input_path}")
            segments, info = model.transcribe(
                str(input_path),
                language=language if language != "auto" else None,
                beam_size=5,
                best_of=5,
                condition_on_previous_text=True,
            )
            detected_language = info.language
            for segment in tqdm(segments, desc="è½¬å½•ä¸­"):
                segments_list.append({
                    "id": segment.id,
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip(),
                })
        else:
            try:
                import whisper
            except Exception:
                result["error"] = "æ— æ³•åŠ è½½ faster-whisperï¼Œä¸”æœªå®‰è£… openai-whisper"
                print("é”™è¯¯: æ— æ³•åŠ è½½ faster-whisperï¼Œä¸”æœªå®‰è£… openai-whisper")
                print("è¿è¡Œ: pip install openai-whisper")
                return result
            
            print(f"åŠ è½½ OpenAI Whisper æ¨¡å‹: {model_size}")
            model = whisper.load_model(model_size)
            
            # æ£€æµ‹è®¾å¤‡å¹¶è®¾ç½® FP16
            fp16 = True
            if model.device.type == "cpu":
                fp16 = False
                print("æ£€æµ‹åˆ° CPU è¿è¡Œï¼Œå·²ç¦ç”¨ FP16 ä»¥é¿å…è­¦å‘Š")
                
            print(f"å¼€å§‹è½¬å½•: {input_path}")
            wres = model.transcribe(str(input_path), language=None if language == "auto" else language, fp16=fp16)
            detected_language = wres.get("language")
            for s in wres.get("segments", []):
                segments_list.append({
                    "id": s.get("id", len(segments_list)),
                    "start": float(s.get("start", 0.0)),
                    "end": float(s.get("end", 0.0)),
                    "text": (s.get("text") or "").strip(),
                })

        result["detected_language"] = detected_language
        if detected_language:
            print(f"æ£€æµ‹åˆ°è¯­è¨€: {detected_language}")

        result["segments"] = segments_list

        transcript_text = "\n".join([s["text"] for s in segments_list])
        transcript_file = output_dir / "transcript.txt"
        with open(transcript_file, "w", encoding="utf-8") as f:
            f.write(transcript_text)
        result["transcript_file"] = str(transcript_file)
        print(f"âœ… è½¬å½•æ–‡æœ¬å·²ä¿å­˜: {transcript_file}")

        srt_file = output_dir / "subtitle_whisper.srt"
        srt_content = generate_srt(segments_list)
        with open(srt_file, "w", encoding="utf-8") as f:
            f.write(srt_content)
        result["srt_file"] = str(srt_file)
        print(f"âœ… SRT å­—å¹•å·²ä¿å­˜: {srt_file}")

        vtt_file = output_dir / "subtitle_whisper.vtt"
        vtt_content = generate_vtt(segments_list)
        with open(vtt_file, "w", encoding="utf-8") as f:
            f.write(vtt_content)
        result["vtt_file"] = str(vtt_file)
        print(f"âœ… VTT å­—å¹•å·²ä¿å­˜: {vtt_file}")

        json_file = output_dir / "transcript.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        result["success"] = True

    except Exception as e:
        result["error"] = str(e)
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")

    return result


def generate_srt(segments: List[dict]) -> str:
    """ç”Ÿæˆ SRT æ ¼å¼çš„å­—å¹•"""
    srt_lines = []
    for segment in segments:
        start = format_time_srt(segment["start"])
        end = format_time_srt(segment["end"])
        srt_lines.append(f"{segment['id'] + 1}")
        srt_lines.append(f"{start} --> {end}")
        srt_lines.append(segment["text"])
        srt_lines.append("")
    return "\n".join(srt_lines)


def generate_vtt(segments: List[dict]) -> str:
    """ç”Ÿæˆ VTT æ ¼å¼çš„å­—å¹•"""
    vtt_lines = ["WEBVTT", ""]
    for segment in segments:
        start = format_time_vtt(segment["start"])
        end = format_time_vtt(segment["end"])
        vtt_lines.append(f"{start} --> {end}")
        vtt_lines.append(segment["text"])
        vtt_lines.append("")
    return "\n".join(vtt_lines)


def format_time_srt(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ HH:MM:SS,mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def format_time_vtt(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸º VTT æ—¶é—´æ ¼å¼ HH:MM:SS.mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"


def extract_audio_from_video(video_path: str, output_dir: str) -> Optional[str]:
    """ä»è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘"""
    try:
        import subprocess
        try:
            import imageio_ffmpeg as i_ffmpeg
            ffmpeg_exe = i_ffmpeg.get_ffmpeg_exe()
        except Exception:
            ffmpeg_exe = "ffmpeg"

        video_path = Path(video_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        audio_path = output_dir / f"{video_path.stem}.mp3"

        if audio_path.exists():
            return str(audio_path)

        print(f"ä»è§†é¢‘ä¸­æå–éŸ³é¢‘åˆ°: {audio_path}")
        cmd = [
            ffmpeg_exe,
            "-i", str(video_path),
            "-vn",
            "-acodec", "libmp3lame",
            "-q:a", "2",
            str(audio_path),
            "-y",
        ]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)

        return str(audio_path) if audio_path.exists() else None

    except Exception as e:
        print(f"æå–éŸ³é¢‘å¤±è´¥: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Whisperè¯­éŸ³è½¬å½•å·¥å…·")
    parser.add_argument(
        "--input", "-i", required=True, help="è¾“å…¥éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output-dir", "-o", default=None, help="è¾“å‡ºç›®å½• (é»˜è®¤: è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•)"
    )
    parser.add_argument(
        "--model", "-m", default="small", help="æ¨¡å‹å¤§å° (é»˜è®¤: small)"
    )
    parser.add_argument(
        "--language", "-l", default="auto", help="è¯­è¨€ä»£ç  (é»˜è®¤: auto)"
    )
    parser.add_argument(
        "--device", "-d", default="auto", help="è®¡ç®—è®¾å¤‡ (cpu/cuda/auto)"
    )
    parser.add_argument(
        "--compute-type", "-c", default="int8", help="è®¡ç®—ç±»å‹ (int8/float16/float32)"
    )
    parser.add_argument(
        "--json", "-j", action="store_true", help="è¾“å‡ºJSONæ ¼å¼"
    )
    parser.add_argument(
        "--engine", "-e", default="auto", choices=["auto", "faster_whisper", "openai_whisper"], help="è½¬å½•å¼•æ“ (é»˜è®¤: auto)"
    )

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = load_config()
    whisper_config = config.get("whisper", {})

    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®
    model_size = args.model or whisper_config.get("model", "small")
    language = args.language or whisper_config.get("language", "auto")

    if args.device == "auto" and whisper_config.get("device"):
        device = whisper_config.get("device")
    else:
        device = args.device

    if args.compute_type == "int8" and whisper_config.get("compute_type"):
        compute_type = whisper_config.get("compute_type")
    else:
        compute_type = args.compute_type

    # ç¡®å®šè¾“å‡ºç›®å½•
    input_path = Path(args.input)
    if args.output_dir:
        output_dir = args.output_dir
    else:
        output_dir = input_path.parent if input_path.is_file() else input_path

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶ç±»å‹
    audio_extensions = {".mp3", ".wav", "flac", ".m4a", ".aac", ".ogg", ".wma"}
    video_extensions = {".mp4", ".avi", ".mov", ".mkv", ".flv", ".wmv", ".webm"}

    # å¦‚æœè¾“å…¥æ˜¯ç›®å½•ï¼Œå°è¯•å¯»æ‰¾è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶
    if input_path.is_dir():
        found_file = None
        # ä¼˜å…ˆæ‰¾è§†é¢‘
        for ext in video_extensions:
            files = list(input_path.glob(f"*{ext}"))
            if files:
                found_file = files[0]
                break
        # æ²¡æ‰¾åˆ°è§†é¢‘æ‰¾éŸ³é¢‘
        if not found_file:
            for ext in audio_extensions:
                files = list(input_path.glob(f"*{ext}"))
                if files:
                    found_file = files[0]
                    break
        
        if found_file:
            print(f"ğŸ“‚ è¾“å…¥æ˜¯ç›®å½•ï¼Œè‡ªåŠ¨é€‰æ‹©æ–‡ä»¶: {found_file.name}")
            input_path = found_file
        else:
            print(f"âŒ ç›®å½•ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„éŸ³è§†é¢‘æ–‡ä»¶: {input_path}")
            sys.exit(1)

    if input_path.suffix.lower() in video_extensions:
        print(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œæ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = extract_audio_from_video(str(input_path), str(output_dir))
        if not audio_path:
            print("âŒ éŸ³é¢‘æå–å¤±è´¥")
            sys.exit(1)
    else:
        audio_path = str(input_path)

    print(f"\nå¼€å§‹è½¬å½•: {audio_path}")
    print(f"æ¨¡å‹: {model_size} | è¯­è¨€: {language} | è®¾å¤‡: {device}")

    result = transcribe_audio(
        input_path=audio_path,
        output_dir=output_dir,
        model_size=model_size,
        language=language,
        device=device,
        compute_type=compute_type,
        engine=args.engine,
    )

    if args.json:
        print("\n" + json.dumps(result, indent=2, ensure_ascii=False))

    if not result["success"]:
        sys.exit(1)

    return result


if __name__ == "__main__":
    main()
