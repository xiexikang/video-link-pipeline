#!/usr/bin/env python3
"""
AI æ™ºèƒ½æ‘˜è¦æ¨¡å— - ä½¿ç”¨ Claude æˆ– OpenAI API ç”Ÿæˆè§†é¢‘å†…å®¹æ‘˜è¦
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional

import yaml
import requests
from dotenv import load_dotenv

load_dotenv()


def load_config(config_path: str = "config.yaml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = {}
    if os.path.exists(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
    return config


def load_transcript(transcript_path: str) -> str:
    """åŠ è½½è½¬å½•æ–‡æœ¬"""
    with open(transcript_path, "r", encoding="utf-8") as f:
        return f.read()


def generate_summary_claude(
    transcript: str,
    api_key: str,
    model: str = "claude-3-5-sonnet-20241022",
    max_tokens: int = 4096,
    temperature: float = 0.3,
) -> Dict:
    """ä½¿ç”¨ Claude API ç”Ÿæˆæ‘˜è¦"""
    try:
        import anthropic

        client = anthropic.Anthropic(api_key=api_key)

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘è½¬å½•æ–‡æœ¬ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ã€‚

è½¬å½•å†…å®¹ï¼š
{transcript[:15000]}  # é™åˆ¶é•¿åº¦ä»¥é¿å…è¶…å‡ºtokené™åˆ¶

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä½¿ç”¨Markdownï¼‰ï¼š

# ğŸ“¹ è§†é¢‘æ‘˜è¦

## ğŸ“Œ ä¸€å¥è¯æ¦‚æ‹¬
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹]

## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- [è¦ç‚¹3]
- [æ›´å¤šè¦ç‚¹...]

## ğŸ’¬ å…³é”®è¯­æ®µ
[åˆ—å‡º3-5ä¸ªé‡è¦çš„å¼•ç”¨æˆ–å…³é”®è¯­æ®µ]

## ğŸ“Š ä¸»é¢˜æ ‡ç­¾
[åˆ—å‡º5-10ä¸ªç›¸å…³æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”]

## â­ æ•´ä½“è¯„ä»·
[å¯¹è§†é¢‘å†…å®¹è´¨é‡ã€ä¿¡æ¯å¯†åº¦ã€å®ç”¨æ€§çš„ç®€çŸ­è¯„ä»·]

åŒæ—¶è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡åŒ…å«ç»“æ„åŒ–æ•°æ®ï¼š
{{
  "one_sentence_summary": "ä¸€å¥è¯æ¦‚æ‹¬",
  "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
  "key_quotes": ["å¼•ç”¨1", "å¼•ç”¨2"],
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"],
  "evaluation": "æ•´ä½“è¯„ä»·",
  "confidence": 0.95  // ç½®ä¿¡åº¦0-1
}}"""

        response = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
        )

        content = response.content[0].text

        # å°è¯•æå– JSON
        result = {
            "raw_response": content,
            "one_sentence_summary": "",
            "key_points": [],
            "key_quotes": [],
            "tags": [],
            "evaluation": "",
            "confidence": 0.0,
            "success": True,
        }

        # å°è¯•è§£æ JSON éƒ¨åˆ†
        try:
            # å¯»æ‰¾ JSON ä»£ç å—
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                json_str = content.split("```")[1].split("```")[0].strip()
            else:
                # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
                start = content.find("{")
                end = content.rfind("}")
                if start != -1 and end != -1:
                    json_str = content[start : end + 1]
                else:
                    json_str = "{}"

            json_data = json.loads(json_str)
            result.update(json_data)
        except Exception as e:
            print(f"âš ï¸  JSON è§£æè­¦å‘Š: {e}")

        return result

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }


def generate_summary_openai_compatible(
    transcript: str,
    api_key: str,
    base_url: str,
    model: str,
    max_tokens: int = 4096,
    temperature: float = 0.3,
) -> Dict:
    try:
        from openai import OpenAI

        client = OpenAI(api_key=api_key, base_url=base_url)

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘è½¬å½•æ–‡æœ¬ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ã€‚

è½¬å½•å†…å®¹ï¼š
{transcript[:15000]}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä½¿ç”¨Markdownï¼‰ï¼š

# ğŸ“¹ è§†é¢‘æ‘˜è¦

## ğŸ“Œ ä¸€å¥è¯æ¦‚æ‹¬
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹]

## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- [è¦ç‚¹3]
- [æ›´å¤šè¦ç‚¹...]

## ğŸ’¬ å…³é”®è¯­æ®µ
[åˆ—å‡º3-5ä¸ªé‡è¦çš„å¼•ç”¨æˆ–å…³é”®è¯­æ®µ]

## ğŸ“Š ä¸»é¢˜æ ‡ç­¾
[åˆ—å‡º5-10ä¸ªç›¸å…³æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”]

## â­ æ•´ä½“è¯„ä»·
[å¯¹è§†é¢‘å†…å®¹è´¨é‡ã€ä¿¡æ¯å¯†åº¦ã€å®ç”¨æ€§çš„ç®€çŸ­è¯„ä»·]

åŒæ—¶è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡åŒ…å«ç»“æ„åŒ–æ•°æ®ã€‚
"""

        response = client.chat.completions.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–è§†é¢‘çš„æ ¸å¿ƒå†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚"},
                {"role": "user", "content": prompt},
            ],
        )

        content = response.choices[0].message.content

        result = {
            "raw_response": content,
            "one_sentence_summary": "",
            "key_points": [],
            "key_quotes": [],
            "tags": [],
            "evaluation": "",
            "confidence": 0.0,
            "success": True,
        }

        try:
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                json_str = content.split("```")[1].split("```")[0].strip()
            else:
                start = content.find("{")
                end = content.rfind("}")
                if start != -1 and end != -1:
                    json_str = content[start : end + 1]
                else:
                    json_str = "{}"
            json_data = json.loads(json_str)
            result.update(json_data)
        except Exception:
            pass

        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }


def generate_summary_gemini(
    transcript: str,
    api_key: str,
    model: str = "gemini-1.5-flash",
    max_tokens: int = 4096,
    temperature: float = 0.3,
) -> Dict:
    try:
        endpoint = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘è½¬å½•æ–‡æœ¬ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ã€‚

è½¬å½•å†…å®¹ï¼š
{transcript[:15000]}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä½¿ç”¨Markdownï¼‰ï¼š

# ğŸ“¹ è§†é¢‘æ‘˜è¦

## ğŸ“Œ ä¸€å¥è¯æ¦‚æ‹¬
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹]

## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- [è¦ç‚¹3]
- [æ›´å¤šè¦ç‚¹...]

## ğŸ’¬ å…³é”®è¯­æ®µ
[åˆ—å‡º3-5ä¸ªé‡è¦çš„å¼•ç”¨æˆ–å…³é”®è¯­æ®µ]

## ğŸ“Š ä¸»é¢˜æ ‡ç­¾
[åˆ—å‡º5-10ä¸ªç›¸å…³æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”]

## â­ æ•´ä½“è¯„ä»·
[å¯¹è§†é¢‘å†…å®¹è´¨é‡ã€ä¿¡æ¯å¯†åº¦ã€å®ç”¨æ€§çš„ç®€çŸ­è¯„ä»·]

åŒæ—¶è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡åŒ…å«ç»“æ„åŒ–æ•°æ®ã€‚
"""

        payload = {
            "contents": [
                {
                    "role": "user",
                    "parts": [{"text": prompt}],
                }
            ],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens,
            },
        }

        r = requests.post(endpoint, json=payload, timeout=60)
        r.raise_for_status()
        data = r.json()

        content_text = ""
        try:
            candidates = data.get("candidates", [])
            if candidates:
                parts = candidates[0].get("content", {}).get("parts", [])
                content_text = "\n".join([p.get("text", "") for p in parts if isinstance(p, dict)])
        except Exception:
            content_text = json.dumps(data, ensure_ascii=False)

        if not content_text:
            content_text = json.dumps(data, ensure_ascii=False)

        result = {
            "raw_response": content_text,
            "one_sentence_summary": "",
            "key_points": [],
            "key_quotes": [],
            "tags": [],
            "evaluation": "",
            "confidence": 0.0,
            "success": True,
        }

        try:
            if "```json" in content_text:
                json_str = content_text.split("```json")[1].split("```")[0].strip()
            elif "```" in content_text:
                json_str = content_text.split("```")[1].split("```")[0].strip()
            else:
                start = content_text.find("{")
                end = content_text.rfind("}")
                if start != -1 and end != -1:
                    json_str = content_text[start : end + 1]
                else:
                    json_str = "{}"
            json_data = json.loads(json_str)
            result.update(json_data)
        except Exception:
            pass

        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }

def generate_summary_openai(
    transcript: str,
    api_key: str,
    model: str = "gpt-4o-mini",
    max_tokens: int = 4096,
    temperature: float = 0.3,
) -> Dict:
    """ä½¿ç”¨ OpenAI API ç”Ÿæˆæ‘˜è¦"""
    try:
        from openai import OpenAI

        client = OpenAI(api_key=api_key)

        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘è½¬å½•æ–‡æœ¬ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ã€‚

è½¬å½•å†…å®¹ï¼š
{transcript[:15000]}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä½¿ç”¨Markdownï¼‰ï¼š

# ğŸ“¹ è§†é¢‘æ‘˜è¦

## ğŸ“Œ ä¸€å¥è¯æ¦‚æ‹¬
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘æ ¸å¿ƒå†…å®¹]

## ğŸ”‘ æ ¸å¿ƒè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- [è¦ç‚¹3]
- [æ›´å¤šè¦ç‚¹...]

## ğŸ’¬ å…³é”®è¯­æ®µ
[åˆ—å‡º3-5ä¸ªé‡è¦çš„å¼•ç”¨æˆ–å…³é”®è¯­æ®µ]

## ğŸ“Š ä¸»é¢˜æ ‡ç­¾
[åˆ—å‡º5-10ä¸ªç›¸å…³æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”]

## â­ æ•´ä½“è¯„ä»·
[å¯¹è§†é¢‘å†…å®¹è´¨é‡ã€ä¿¡æ¯å¯†åº¦ã€å®ç”¨æ€§çš„ç®€çŸ­è¯„ä»·]

åŒæ—¶è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡åŒ…å«ç»“æ„åŒ–æ•°æ®ã€‚
"""

        response = client.chat.completions.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–è§†é¢‘çš„æ ¸å¿ƒå†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
        )

        content = response.choices[0].message.content

        result = {
            "raw_response": content,
            "one_sentence_summary": "",
            "key_points": [],
            "key_quotes": [],
            "tags": [],
            "evaluation": "",
            "confidence": 0.0,
            "success": True,
        }

        # å°è¯•è§£æ JSON
        try:
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                json_str = content.split("```")[1].split("```")[0].strip()
            else:
                start = content.find("{")
                end = content.rfind("}")
                if start != -1 and end != -1:
                    json_str = content[start : end + 1]
                else:
                    json_str = "{}"

            json_data = json.loads(json_str)
            result.update(json_data)
        except Exception:
            pass

        return result

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }


def generate_summary(
    transcript_path: str,
    output_dir: str,
    config: dict,
) -> Dict:
    """
    ç”Ÿæˆè§†é¢‘å†…å®¹æ‘˜è¦

    Args:
        transcript_path: è½¬å½•æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        config: é…ç½®å­—å…¸

    Returns:
        dict: æ‘˜è¦ç»“æœ
    """
    transcript_path = Path(transcript_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½è½¬å½•æ–‡æœ¬
    try:
        transcript = load_transcript(str(transcript_path))
    except Exception as e:
        return {
            "success": False,
            "error": f"æ— æ³•åŠ è½½è½¬å½•æ–‡ä»¶: {e}",
        }

    if not transcript.strip():
        return {
            "success": False,
            "error": "è½¬å½•æ–‡ä»¶ä¸ºç©º",
        }

    summary_config = config.get("summary", {})
    provider = summary_config.get("provider", "claude")

    # è·å– API Key
    api_keys = config.get("api_keys", {})
    api_key = None

    if provider == "claude":
        api_key = api_keys.get("claude") or os.getenv("ANTHROPIC_API_KEY")
    elif provider == "openai":
        api_key = api_keys.get("openai") or os.getenv("OPENAI_API_KEY")
    elif provider == "gemini":
        api_key = api_keys.get("gemini") or os.getenv("GEMINI_API_KEY")
    elif provider == "deepseek":
        api_key = api_keys.get("deepseek") or os.getenv("DEEPSEEK_API_KEY")
    elif provider in {"kimi", "moonshot"}:
        api_key = api_keys.get("kimi") or api_keys.get("moonshot") or os.getenv("KIMI_API_KEY") or os.getenv("MOONSHOT_API_KEY")
    elif provider == "minimax":
        api_key = api_keys.get("minimax") or os.getenv("MINIMAX_API_KEY")
    elif provider in {"glm", "zhipu"}:
        api_key = api_keys.get("glm") or api_keys.get("zhipu") or os.getenv("GLM_API_KEY") or os.getenv("ZHIPU_API_KEY")
    else:
        api_key = None

    if not api_key:
        return {
            "success": False,
            "error": f"æœªè®¾ç½® {provider} API Keyã€‚è¯·åœ¨ config.yaml ä¸­é…ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ã€‚",
        }

    # ç”Ÿæˆæ‘˜è¦
    print(f"ä½¿ç”¨ {provider} ç”Ÿæˆæ‘˜è¦...")

    if provider == "claude":
        result = generate_summary_claude(
            transcript=transcript,
            api_key=api_key,
            model=summary_config.get("model", "claude-3-5-sonnet-20241022"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider == "openai":
        result = generate_summary_openai(
            transcript=transcript,
            api_key=api_key,
            model=summary_config.get("model", "gpt-4o-mini"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider == "gemini":
        result = generate_summary_gemini(
            transcript=transcript,
            api_key=api_key,
            model=summary_config.get("model", "gemini-1.5-flash"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider == "deepseek":
        result = generate_summary_openai_compatible(
            transcript=transcript,
            api_key=api_key,
            base_url=summary_config.get("base_url", "https://api.deepseek.com"),
            model=summary_config.get("model", "deepseek-chat"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider in {"kimi", "moonshot"}:
        result = generate_summary_openai_compatible(
            transcript=transcript,
            api_key=api_key,
            base_url=summary_config.get("base_url", "https://api.moonshot.cn/v1"),
            model=summary_config.get("model", "moonshot-v1-8k"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider == "minimax":
        result = generate_summary_openai_compatible(
            transcript=transcript,
            api_key=api_key,
            base_url=summary_config.get("base_url", "https://api.minimax.chat/v1"),
            model=summary_config.get("model", "abab5.5-chat"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    elif provider in {"glm", "zhipu"}:
        result = generate_summary_openai_compatible(
            transcript=transcript,
            api_key=api_key,
            base_url=summary_config.get("base_url", "https://open.bigmodel.cn/api/paas/v4"),
            model=summary_config.get("model", "glm-4"),
            max_tokens=summary_config.get("max_tokens", 4096),
            temperature=summary_config.get("temperature", 0.3),
        )
    else:
        result = {
            "success": False,
            "error": f"ä¸æ”¯æŒçš„ provider: {provider}",
        }

    if result["success"]:
        # ä¿å­˜ Markdown æ ¼å¼æ‘˜è¦
        summary_md = output_dir / "summary.md"
        with open(summary_md, "w", encoding="utf-8") as f:
            f.write(result.get("raw_response", ""))
        print(f"âœ… Markdown æ‘˜è¦å·²ä¿å­˜: {summary_md}")

        # ä¿å­˜ JSON æ ¼å¼æ•°æ®
        keywords_json = output_dir / "keywords.json"
        json_data = {
            "one_sentence_summary": result.get("one_sentence_summary", ""),
            "key_points": result.get("key_points", []),
            "key_quotes": result.get("key_quotes", []),
            "tags": result.get("tags", []),
            "evaluation": result.get("evaluation", ""),
            "confidence": result.get("confidence", 0.0),
        }
        with open(keywords_json, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å…³é”®è¯æ•°æ®å·²ä¿å­˜: {keywords_json}")

        result["summary_file"] = str(summary_md)
        result["keywords_file"] = str(keywords_json)

    return result


def main():
    parser = argparse.ArgumentParser(description="AI è§†é¢‘æ‘˜è¦ç”Ÿæˆå·¥å…·")
    parser.add_argument(
        "--transcript", "-t", required=True, help="è½¬å½•æ–‡æœ¬æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output-dir", "-o", default=None, help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--provider", "-p",
        choices=["claude", "openai", "gemini", "deepseek", "kimi", "moonshot", "minimax", "glm", "zhipu"],
        help="AI æä¾›å•† (è¦†ç›–é…ç½®)"
    )
    parser.add_argument(
        "--api-key", "-k", help="API Key (è¦†ç›–é…ç½®)"
    )
    parser.add_argument(
        "--json", "-j", action="store_true", help="è¾“å‡ºJSONæ ¼å¼"
    )
    parser.add_argument(
        "--model", help="æ¨¡å‹å (è¦†ç›–é…ç½®)"
    )
    parser.add_argument(
        "--base-url", help="å…¼å®¹æ¥å£ Base URL (è¦†ç›–é…ç½®)"
    )

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = load_config()

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.provider:
        if "summary" not in config:
            config["summary"] = {}
        
        # å¦‚æœåˆ‡æ¢äº† provider ä¸”æ²¡æœ‰æŒ‡å®š modelï¼Œåˆ™æ¸…é™¤ config ä¸­çš„ modelï¼Œ
        # é¿å…æ²¿ç”¨æ—§ provider çš„æ¨¡å‹é…ç½®
        old_provider = config.get("summary", {}).get("provider")
        if old_provider != args.provider and not args.model:
            if "model" in config.get("summary", {}):
                del config["summary"]["model"]

        config["summary"]["provider"] = args.provider

    if args.api_key:
        if "api_keys" not in config:
            config["api_keys"] = {}
        if config.get("summary", {}).get("provider") == "claude":
            config["api_keys"]["claude"] = args.api_key
        else:
            config["api_keys"]["openai"] = args.api_key
    if args.model:
        if "summary" not in config:
            config["summary"] = {}
        config["summary"]["model"] = args.model
    if args.base_url:
        if "summary" not in config:
            config["summary"] = {}
        config["summary"]["base_url"] = args.base_url

    # ç¡®å®šè¾“å‡ºç›®å½•
    transcript_path = Path(args.transcript)
    if args.output_dir:
        output_dir = args.output_dir
    else:
        output_dir = transcript_path.parent

    print(f"è½¬å½•æ–‡ä»¶: {transcript_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print()

    result = generate_summary(
        transcript_path=str(transcript_path),
        output_dir=output_dir,
        config=config,
    )

    if result["success"]:
        print(f"\nâœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ!")
        if result.get("one_sentence_summary"):
            print(f"\nä¸€å¥è¯æ¦‚æ‹¬:")
            print(f"  {result['one_sentence_summary']}")
        if result.get("tags"):
            print(f"\nä¸»é¢˜æ ‡ç­¾: {', '.join(result['tags'])}")
    else:
        print(f"\nâŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {result.get('error')}")
        sys.exit(1)

    if args.json:
        print("\n" + json.dumps(result, indent=2, ensure_ascii=False))

    return result


if __name__ == "__main__":
    main()
